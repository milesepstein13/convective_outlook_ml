{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c87307c-c45a-40cd-a668-fb01cbb6b91c",
   "metadata": {},
   "source": [
    "This notebook will compare model architecture, hyperparameters, inputs, and training/validation error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7640bc2-c69c-4959-9d04-e4bf91e1fc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from src.crossval import run_crossval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bf77751",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = \"/glade/work/milesep/convective_outlook_ml\"\n",
    "target_dir = \"data/processed_data\"\n",
    "stats_dir = \"data/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "574e71ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict_mean small 0.005 32\n",
      "Using device: cuda\n",
      "\n",
      "Fold 0:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:22<00:00,  1.64s/epoch, train_loss=1.0004, val_loss=1.0019]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:21<00:00,  1.63s/epoch, train_loss=0.9406, val_loss=1.2400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:24<00:00,  1.68s/epoch, train_loss=0.9996, val_loss=1.0048]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:22<00:00,  1.65s/epoch, train_loss=1.0149, val_loss=0.9478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:23<00:00,  1.68s/epoch, train_loss=1.0397, val_loss=0.8430]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging average losses...\n",
      "Reading fold 0\n",
      "Reading fold 1\n",
      "Reading fold 2\n",
      "Reading fold 3\n",
      "Reading fold 4\n",
      "predict_mean: 1.008 ± 0.130\n",
      "predict_zero small 0.005 32\n",
      "Using device: cuda\n",
      "\n",
      "Fold 0:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:24<00:00,  1.69s/epoch, train_loss=1.0011, val_loss=0.9956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:22<00:00,  1.65s/epoch, train_loss=0.9417, val_loss=1.2307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:23<00:00,  1.67s/epoch, train_loss=1.0002, val_loss=0.9991]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:25<00:00,  1.70s/epoch, train_loss=1.0164, val_loss=0.9339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 50/50 [01:23<00:00,  1.67s/epoch, train_loss=1.0404, val_loss=0.8373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging average losses...\n",
      "Reading fold 0\n",
      "Reading fold 1\n",
      "Reading fold 2\n",
      "Reading fold 3\n",
      "Reading fold 4\n",
      "predict_zero: 1.000 ± 0.130\n",
      "predict_mean slgt_small 0.005 32\n",
      "Using device: cuda\n",
      "\n",
      "Fold 0:\n",
      "Loading data...\n",
      "Standardizing data...\n",
      "Setting up datasets...\n",
      "Model has no parameters — skipping device check\n",
      "Starting training from scratch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   2%|▏         | 1/50 [00:22<18:09, 22.23s/epoch, train_loss=0.9574, val_loss=1.1708]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m targets \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train_targets\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mslgt_mod_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m stats \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mopen_dataset(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstats_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/daily_input_stats_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlevel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m scores, train_counts, val_counts \u001b[38;5;241m=\u001b[39m \u001b[43mrun_crossval\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrestart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39maverage(scores,\u001b[38;5;250m \u001b[39mweights\u001b[38;5;250m \u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;250m \u001b[39mval_counts)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ± \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mstd(scores)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/convective_outlook_ml/src/crossval.py:159\u001b[0m, in \u001b[0;36mrun_crossval\u001b[0;34m(X, y, stats, model_name, n_splits, batch_size, epochs, optimizer_class, lr, criterion, level, restart, force_cpu)\u001b[0m\n\u001b[1;32m    156\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(\u001b[38;5;28mrange\u001b[39m(start_epoch, epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# print(\"Training...\")\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;66;03m# print(\"Validating...\")\u001b[39;00m\n\u001b[1;32m    161\u001b[0m     val_loss, all_preds, all_targets \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion, device, epoch, writer)\n",
      "File \u001b[0;32m~/convective_outlook_ml/src/train_loop.py:10\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, loader, optimizer, criterion, device, epoch, writer, no_params)\u001b[0m\n\u001b[1;32m      8\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m      9\u001b[0m total_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# print('a')\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_y\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/glade/work/milesep/conda-envs/mlco/lib/python3.11/site-packages/torch/utils/data/dataloader.py:734\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    733\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 734\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    739\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    740\u001b[0m ):\n",
      "File \u001b[0;32m/glade/work/milesep/conda-envs/mlco/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1492\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data, worker_id)\n\u001b[1;32m   1491\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1492\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/milesep/conda-envs/mlco/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1444\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m   1443\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[0;32m-> 1444\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1445\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1446\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/glade/work/milesep/conda-envs/mlco/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1285\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1272\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1273\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1274\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1282\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1285\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1286\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[1;32m   1287\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1288\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1290\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m/glade/work/milesep/conda-envs/mlco/lib/python3.11/queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[0;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[0;32m/glade/work/milesep/conda-envs/mlco/lib/python3.11/threading.py:331\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 331\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    333\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compare all models, save training and validation curves along with corresponding model name, data level, model/training hyperparameters\n",
    "model_names = [\n",
    "    \"linear_regression\", \"cnn3d_dropout_0_5\", \"cnn3d_dropout_5_5\", \"cnn3d_dropout_5_0\", \"cnn3d\",\n",
    "    \"cnn3d_gelu_0_5\", \"cnn3d_gelu_0_5\", \"cnn3d_gelu_0_5\", \"cnn3d_gelu_0_5\",\n",
    "    \"cnn3d_gelu_0_5\", \"cnn3d_gelu_0_5\", \"cnn3d_gelu_0_5\",\n",
    "    \"cnn3d_gelu_0_5\", \"cnn3d_gelu_0_5\", \"cnn3d_gelu_0_5\",\n",
    "    \"cnn3d_gelu_0_5\", \"cnn3d_dropout_5_5\", \"cnn3d_dropout_5_0\",\n",
    "    \"cnn3d_gelu_2_6\", \"cnn3d_gelu_2_6\",\n",
    "    \"cnn3d_big_kernal\", \"cnn3d_huge_kernal\",\n",
    "    \"cnn3d_3_layer\", \"cnn3d_3_layer_big\", \"cnn3d_fewer_channels\", \"cnn3d_3_layer_fewer_channels\",\n",
    "    # --- slgt_small ---\n",
    "    \"cnn3d_gelu_2_6\", \"cnn3d_gelu_0_5\", \"cnn3d_3_layer\", \"cnn3d_fewer_channels\", \"cnn3d_3_layer_big\",\n",
    "    \"cnn3d_gelu_2_6\", \"cnn3d_gelu_2_6\", \"cnn3d_gelu_2_6\", \"cnn3d_gelu_2_6\",\n",
    "    \"cnn3d_3_layer_fewer_channels\", \"cnn3d_3_layer_big\", \"cnn3d_3_layer\", \"cnn3d_3_layer_1_3\",\n",
    "    \"cnn3d_3_layer_fewer_channels_1_3\",\n",
    "    \"cnn3d_3_layer_fewer_channels\", \"cnn3d_3_layer_big\", \"cnn3d_3_layer\", \"cnn3d_3_layer_1_3\",\n",
    "    \"cnn3d_3_layer_big_1_3\", \"cnn3d_3_layer_fewer_channels_1_3\",\n",
    "    \"cnn3d_4_layer\", \"cnn3d_3_layer_big_0\", \"cnn3d_3_layer_big_1_3\",\n",
    "    \"cnn3d_4_layer_1_3\", \"cnn3d_4_layer_big\", \"cnn3d_4_layer_big_1_3\", \"predict_zero\", \"predict_mean\",\n",
    "    # --- full ---\n",
    "    \"cnn3d_gelu_0_5\", \"cnn3d_gelu_2_6\", \"cnn3d_big_kernal\", \"cnn3d_huge_kernal\",\n",
    "    \"cnn3d_3_layer\", \"cnn3d_3_layer_big\", \"cnn3d_fewer_channels\", \"cnn3d_3_layer_fewer_channels\"\n",
    "]\n",
    "\n",
    "levels = [\n",
    "    # small\n",
    "    *[\"small\"]*26,\n",
    "    # slgt_small\n",
    "    *[\"slgt_small\"]*27,\n",
    "    # full\n",
    "    *[\"full\"]*9\n",
    "]\n",
    "\n",
    "lrs = [\n",
    "    # small\n",
    "    1e-3, 1e-3, 1e-3, 1e-3, 1e-3,\n",
    "    1e-3, 1e-3, 1e-3, 1e-3,\n",
    "    1e-4, 1e-4, 1e-4,\n",
    "    4e-4, 4e-4, 4e-4,\n",
    "    1e-3, 1e-3, 1e-3,\n",
    "    1e-3, 1e-3,\n",
    "    1e-3, 1e-3,\n",
    "    1e-3, 1e-3, 1e-3, 1e-3,\n",
    "    # slgt_small\n",
    "    1e-3, 1e-3, 1e-3, 1e-3, 1e-3,\n",
    "    1e-4, 1e-4, 5e-3, 5e-3,\n",
    "    5e-3, 5e-3, 5e-3, 5e-3,\n",
    "    5e-3,\n",
    "    1e-2, 1e-2, 1e-2, 1e-2,\n",
    "    1e-2, 1e-2,\n",
    "    5e-3, 5e-3, 5e-3,\n",
    "    5e-3, 5e-3, 5e-3, 5e-3, 5e-3,\n",
    "    # full\n",
    "    1e-3, 1e-3, 1e-3, 1e-3,\n",
    "    1e-3, 1e-3, 1e-3, 1e-3, 1e-3\n",
    "]\n",
    "\n",
    "batch_sizes = [\n",
    "    # small\n",
    "    32, 32, 32, 32, 32,\n",
    "    32, 4, 8, 32,\n",
    "    4, 8, 32,\n",
    "    4, 8, 32,\n",
    "    64, 64, 64,\n",
    "    64, 8,\n",
    "    8, 8,\n",
    "    8, 8, 8, 8,\n",
    "    # slgt_small\n",
    "    8, 8, 8, 8, 8,\n",
    "    4, 32, 4, 32,\n",
    "    32, 32, 32, 32,\n",
    "    32,\n",
    "    64, 64, 64, 64,\n",
    "    64, 64,\n",
    "    32, 32, 32,\n",
    "    32, 32, 32, 32, 32,\n",
    "    # full\n",
    "    8, 8, 8, 8,\n",
    "    8, 8, 8, 8, 8\n",
    "]\n",
    "\n",
    "epochs = [50] * len(model_names)\n",
    "# restarts = [True, False, False, False, False, False, False, False, False, False, False]\n",
    "# Don't do linear regression with full dataset--too many parameters\n",
    "for name, level, lr, batch_size, epoch in zip(model_names, levels, lrs, batch_sizes, epochs):\n",
    "    if level[:4] == 'slgt':\n",
    "        slgt_mod_str = '_slgt'\n",
    "    else:\n",
    "        slgt_mod_str = ''\n",
    "    print(name, level, lr, batch_size)\n",
    "    inputs = xr.open_zarr(f\"{input_dir}/train_inputs_{level}.zarr\")\n",
    "    targets = xr.open_dataset(f\"{target_dir}/train_targets{slgt_mod_str}.nc\")\n",
    "    stats = xr.open_dataset(f\"{stats_dir}/daily_input_stats_{level}.nc\")\n",
    "    scores, train_counts, val_counts = run_crossval(inputs, targets, stats, name, batch_size = batch_size, lr = lr, epochs = epoch, level = level, restart = True)\n",
    "    print(f\"{name}: {np.average(scores, weights = val_counts):.3f} ± {np.std(scores):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlco]",
   "language": "python",
   "name": "conda-env-mlco-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
